<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Noisy Tensor Completion via the Sum-of-Squares Hierarchy | COLT 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Noisy Tensor Completion via the Sum-of-Squares Hierarchy">

  <meta name="citation_author" content="Barak, Boaz">

  <meta name="citation_author" content="Moitra, Ankur">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="29th Annual Conference on Learning Theory">
<meta name="citation_firstpage" content="417">
<meta name="citation_lastpage" content="445">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v49/barak16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Noisy Tensor Completion via the Sum-of-Squares Hierarchy</h1>

	<div id="authors">
	
		Boaz Barak,
	
		Ankur Moitra
	<br />
	</div>
	<div id="info">
		29th Annual Conference on Learning Theory,
		pp. 417–445, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		<p>In the noisy tensor completion problem we observe <span class="math">\(m\)</span> entries (whose location is chosen uniformly at random) from an unknown <span class="math">\(n_1 \times n_2 \times n_3\)</span> tensor <span class="math">\(T\)</span>. We assume that <span class="math">\(T\)</span> is entry-wise close to being rank <span class="math">\(r\)</span>. Our goal is to fill in its missing entries using as few observations as possible. Let <span class="math">\(n = \max(n_1, n_2, n_3)\)</span>. We show that if <span class="math">\(m =  n^{3/2} r\)</span> then there is a polynomial time algorithm based on the sixth level of the sum-of-squares hierarchy for completing it. Our estimate agrees with almost all of <span class="math">\(T\)</span>’s entries almost exactly and works even when our observations are corrupted by noise. This is also the first algorithm for tensor completion that works in the overcomplete case when <span class="math">\(r &gt; n\)</span>, and in fact it works all the way up to <span class="math">\(r = n^{3/2-\epsilon}\)</span>.</p>
<p>Our proofs are short and simple and are based on establishing a new connection between noisy tensor completion (through the language of Rademacher complexity) and the task of refuting random constant satisfaction problems. This connection seems to have gone unnoticed even in the context of matrix completion. Furthermore, we use this connection to show matching lower bounds. Our main technical result is in characterizing the Rademacher complexity of the sequence of norms that arise in the sum-of-squares relaxations to the tensor nuclear norm. These results point to an interesting new direction: Can we explore computational vs. sample complexity tradeoffs through the sum-of-squares hierarchy?</p>
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="barak16.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
