<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Complexity Theoretic Limitations on Learning DNF’s | COLT 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Complexity Theoretic Limitations on Learning DNF's">

  <meta name="citation_author" content="Daniely, Amit">

  <meta name="citation_author" content="Shalev-Shwartz, Shai">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="29th Annual Conference on Learning Theory">
<meta name="citation_firstpage" content="815">
<meta name="citation_lastpage" content="830">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v49/daniely16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Complexity Theoretic Limitations on Learning DNF’s</h1>

	<div id="authors">
	
		Amit Daniely,
	
		Shai Shalev-Shwartz
	<br />
	</div>
	<div id="info">
		29th Annual Conference on Learning Theory,
		pp. 815–830, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Using the recently developed framework of Daniely, Linial and Shalev-Shwartz, we show that under a natural assumption on the complexity of random K-SAT, learning DNF formulas is hard. Furthermore, the same assumption implies the hardness of various learning problems, including intersections of logarithmically many halfspaces, agnostically learning conjunctions, as well as virtually all (distribution free) learning problems that were previously shown hard (under various complexity assumptions).
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="daniely16.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
