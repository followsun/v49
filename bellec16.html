<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Aggregation of supports along the Lasso path | COLT 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Aggregation of supports along the Lasso path">

  <meta name="citation_author" content="Bellec, Pierre C.">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="29th Annual Conference on Learning Theory">
<meta name="citation_firstpage" content="488">
<meta name="citation_lastpage" content="529">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v49/bellec16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Aggregation of supports along the Lasso path</h1>

	<div id="authors">
	
		Pierre C. Bellec
	<br />
	</div>
	<div id="info">
		29th Annual Conference on Learning Theory,
		pp. 488â€“529, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		In linear regression with fixed design, we propose two procedures that aggregate a data-driven collection of supports. The collection is a subset of the <span class="math">\(2^p\)</span> possible supports and both its cardinality and its elements can depend on the data. The procedures satisfy oracle inequalities with no assumption on the design matrix. Then we use these procedures to aggregate the supports that appear on the regularization path of the Lasso in order to construct an estimator that mimics the best Lasso estimator. If the restricted eigenvalue condition on the design matrix is satisfied, then this estimator achieves optimal prediction bounds. Finally, we discuss the computational cost of these procedures.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="bellec16.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
