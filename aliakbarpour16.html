<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Learning and Testing Junta Distributions | COLT 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Learning and Testing Junta Distributions">

  <meta name="citation_author" content="Aliakbarpour, Maryam">

  <meta name="citation_author" content="Blais, Eric">

  <meta name="citation_author" content="Rubinfeld, Ronitt">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="29th Annual Conference on Learning Theory">
<meta name="citation_firstpage" content="19">
<meta name="citation_lastpage" content="46">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v49/aliakbarpour16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Learning and Testing Junta Distributions</h1>

	<div id="authors">
	
		Maryam Aliakbarpour,
	
		Eric Blais,
	
		Ronitt Rubinfeld
	<br />
	</div>
	<div id="info">
		29th Annual Conference on Learning Theory,
		pp. 19â€“46, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		<p>We consider the problem of learning distributions in the presence of irrelevant features. This problem is formalized by introducing a new notion of <em><span class="math">\(k\)</span>-junta distributions</em>. Informally, a distribution <span class="math">\(\mathcal{D}\)</span> over the domain <span class="math">\(\mathcal{X}^n\)</span> is a <em><span class="math">\(k\)</span>-junta distribution</em> with respect to another distribution <span class="math">\(\mathcal{U}\)</span> over the same domain if there is a set <span class="math">\(J \subseteq [n]\)</span> of size <span class="math">\(|J| \le k\)</span> that captures the difference between <span class="math">\(\mathcal {D}\)</span> and <span class="math">\(\mathcal{U}\)</span>.</p>
<p>We show that it is possible to learn <span class="math">\(k\)</span>-junta distributions with respect to the uniform distribution over the Boolean hypercube <span class="math">\(\{0,1\}^n\)</span> in time <span class="math">\(\poly(n^k, 1/\epsilon)\)</span>. This result is obtained via a new Fourier-based learning algorithm inspired by the Low-Degree Algorithm of Linial, Mansour, and Nisan (1993).</p>
<p>We also consider the problem of testing whether an unknown distribution is a <span class="math">\(k\)</span>-junta distribution with respect to the uniform distribution. We give a nearly-optimal algorithm for this task. Both the analysis of the algorithm and the lower bound showing its optimality are obtained by establishing connections between the problem of testing junta distributions and testing uniformity of weighted collections of distributions.</p>
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="aliakbarpour16.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
