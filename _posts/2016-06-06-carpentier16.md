---
title: Tight (Lower) Bounds for the Fixed Budget Best Arm Identification Bandit Problem
abstract: We consider the problem of \textitbest arm identification with a \textitfixed
  budget T, in the K-armed stochastic bandit setting, with arms distribution defined
  on [0,1]. We prove that any bandit strategy, for at least one bandit problem characterized
  by a complexity H, will misidentify the best arm with probability lower bounded
  by $\exp\Big(-\fracT\log(K)H\Big), where H is the sum for all sub-optimal arms of
  the inverse of the squared gaps. Our result disproves formally the general belief
  - coming from results in the fixed confidence setting - that there must exist an
  algorithm for this problem whose probability of error is upper bounded by \exp(-T/H)$.
  This also proves that some existing strategies based on the Successive Rejection
  of the arms are optimal - closing therefore the current gap between upper and lower
  bounds for the fixed budget best arm identification problem.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: carpentier16
month: 0
firstpage: 590
lastpage: 604
page: 590-604
sections: 
author:
- given: Alexandra
  family: Carpentier
- given: Andrea
  family: Locatelli
date: 2016-06-06
address: Columbia University, New York, New York, USA
publisher: PMLR
container-title: 29th Annual Conference on Learning Theory
volume: '49'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 6
pdf: http://proceedings.mlr.press/v49/carpentier16/carpentier16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
