---
title: Complexity Theoretic Limitations on Learning DNFâ€™s
abstract: 'Using the recently developed framework of Daniely, Linial and Shalev-Shwartz,
  we show that under a natural assumption on the complexity of random K-SAT, learning
  DNF formulas is hard. Furthermore, the same assumption implies the hardness of various
  learning problems, including intersections of logarithmically many halfspaces, agnostically
  learning conjunctions, as well as virtually all (distribution free) learning problems
  that were previously shown hard (under various complexity assumptions). '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: daniely16
month: 0
tex_title: Complexity Theoretic Limitations on Learning DNF's
firstpage: 815
lastpage: 830
page: 815-830
order: 815
cycles: false
author:
- given: Amit
  family: Daniely
- given: Shai
  family: Shalev-Shwartz
date: 2016-06-06
address: Columbia University, New York, New York, USA
publisher: PMLR
container-title: 29th Annual Conference on Learning Theory
volume: '49'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 6
pdf: http://proceedings.mlr.press/v49/daniely16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
