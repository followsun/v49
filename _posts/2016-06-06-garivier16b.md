---
title: 'Maximin Action Identification: A New Bandit Framework for Games'
abstract: 'We study an original problem of pure exploration in a strategic bandit
  model motivated by Monte Carlo Tree Search. It consists in identifying the best
  action in a game, when the player may sample random outcomes of sequentially chosen
  pairs of actions. We propose two strategies for the fixed-confidence setting: Maximin-LUCB,
  based on lower- and upper- confidence bounds; and Maximin-Racing, which operates
  by successively eliminating the sub-optimal actions. We discuss the sample complexity
  of both methods and compare their performance empirically. We sketch a lower bound
  analysis, and possible connections to an optimal algorithm.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: garivier16b
month: 0
firstpage: 1028
lastpage: 1050
page: 1028-1050
sections: 
author:
- given: Aur√©lien
  family: Garivier
- given: Emilie
  family: Kaufmann
- given: Wouter M.
  family: Koolen
date: 2016-06-06
address: Columbia University, New York, New York, USA
publisher: PMLR
container-title: 29th Annual Conference on Learning Theory
volume: '49'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 6
pdf: http://proceedings.mlr.press/v49/garivier16b.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
