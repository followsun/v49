---
title: An efficient algorithm for contextual bandits with knapsacks, and an extension
  to concave objectives
abstract: 'We consider a contextual version of multi-armed bandit problem with global
  knapsack constraints. In each round, the outcome of pulling an arm is a scalar reward
  and a resource consumption vector, both dependent on the context, and the global
  knapsack constraints require the total consumption for each resource to be below
  some pre-fixed budget. The learning agent competes with an arbitrary set of context-dependent
  policies. This problem was introduced by Badanidiyuru et al., who gave a computationally
  inefficient algorithm with near-optimal regret bounds for it.  We give a \emphcomputationally
  efficient algorithm for this problem with slightly better regret bounds, by generalizing
  the approach of Dudik et al. for the non-constrained version of the problem. The
  computational time of our algorithm scales \emphlogarithmically in the size of the
  policy space. This answers the main open question of Badanidiyuru et al. We also
  extend our results to a variant where there are no knapsack constraints but the
  objective is an arbitrary Lipschitz concave function of the sum of outcome vectors. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: agrawal16
month: 0
firstpage: 4
lastpage: 18
page: 4-18
sections: 
author:
- given: Shipra
  family: Agrawal
- given: Nikhil R.
  family: Devanur
- given: Lihong
  family: Li
date: 2016-06-06
address: Columbia University, New York, New York, USA
publisher: PMLR
container-title: 29th Annual Conference on Learning Theory
volume: '49'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 6
pdf: http://proceedings.mlr.press/v49/agrawal16/agrawal16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
