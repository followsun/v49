---
title: 'Open Problem: Parameter-Free and Scale-Free Online Algorithms'
abstract: 'Existing vanilla algorithms for online linear optimization have O((ηR(u)
  + 1/η) \sqrtT) regret with respect to any competitor u, where R(u) is a 1-strongly
  convex regularizer and η> 0 is a tuning parameter of the algorithm. For certain
  decision sets and regularizers, the so-called \emphparameter-free algorithms have
  \widetilde O(\sqrtR(u) T) regret with respect to any competitor u.  Vanilla algorithm
  can achieve the same bound only for a fixed competitor u known ahead of time by
  setting η= 1/\sqrtR(u). A drawback of both vanilla and parameter-free algorithms
  is that they assume that the norm of the loss vectors is bounded by a constant known
  to the algorithm. There exist \emphscale-free algorithms that have O((ηR(u) + 1/η)
  \sqrtT \max_1 \le t \le T \norm\ell_t) regret with respect to any competitor u and
  for any sequence of loss vector \ell_1, …, \ell_T. Parameter-free analogue of scale-free
  algorithms have never been designed. Is is possible to design algorithms that are
  simultaneously \emphparameter-free and \emphscale-free? '
section: open
layout: inproceedings
series: Proceedings of Machine Learning Research
id: orabona16
month: 0
tex_title: 'Open Problem: Parameter-Free and Scale-Free Online Algorithms'
firstpage: 1659
lastpage: 1664
page: 1659-1664
order: 1659
cycles: false
author:
- given: Francesco
  family: Orabona
- given: Dávid
  family: Pál
date: 2016-06-06
address: Columbia University, New York, New York, USA
publisher: PMLR
container-title: 29th Annual Conference on Learning Theory
volume: '49'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 6
pdf: http://proceedings.mlr.press/v49/orabona16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
