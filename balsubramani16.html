<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Instance-dependent Regret Bounds for Dueling Bandits | COLT 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Instance-dependent Regret Bounds for Dueling Bandits">

  <meta name="citation_author" content="Balsubramani, Akshay">

  <meta name="citation_author" content="Karnin, Zohar">

  <meta name="citation_author" content="Schapire, Robert E.">

  <meta name="citation_author" content="Zoghi, Masrour">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="29th Annual Conference on Learning Theory">
<meta name="citation_firstpage" content="336">
<meta name="citation_lastpage" content="360">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v49/balsubramani16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Instance-dependent Regret Bounds for Dueling Bandits</h1>

	<div id="authors">
	
		Akshay Balsubramani,
	
		Zohar Karnin,
	
		Robert E. Schapire,
	
		Masrour Zoghi
	<br />
	</div>
	<div id="info">
		29th Annual Conference on Learning Theory,
		pp. 336â€“360, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We study the multi-armed dueling bandit problem in which feedback is provided in the form of relative comparisons between pairs of actions, with the goal of eventually learning to select actions that are close to the best. Following Dudik et al. (2015), we aim for algorithms whose performance approaches that of the optimal randomized choice of actions, the von Neumann winner, expressly avoiding more restrictive assumptions, for instance, regarding the existence of a single best action (a Condorcet winner). In this general setting, the best known algorithms achieve regret O() in T rounds with K actions. In this paper, we present the first instance-dependent regret bounds for the general problem, focusing particularly on when the von Neumann winner is sparse. Specifically, we propose a new algorithm whose regret, relative to a unique von Neumann winner with sparsity s, is at most O(), plus an instance-dependent constant. Thus, when the sparsity is much smaller than the total number of actions, our result indicates that learning can be substantially faster.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="balsubramani16.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
